# Directions

Students are encouraged to work together on homework. However, sharing, copying or providing any part of a homework solution or code is an infraction of the University's rules on Academic Integrity. Any violation will be punished as severely as possible.

Final submissions must be uploaded to our Compass 2g site on the Homework page. No email, hardcopy, or late submissions will be accepted.

- Your assignment must be submitted through the [submission link](https://compass2g.illinois.edu/webapps/assignment/uploadAssignment?content_id=_2326191_1&course_id=_28042_1&assign_group_id=&mode=cpview) on **Compass 2g.** You are required to attach one `.zip` file, named `hw07_yourNetID.zip`, which contains:
    - Your RMarkdown file which should be saved as `hw07_yourNetID.Rmd`. For example `hw07_dunger.Rmd`.
    - The result of knitting your RMarkdown file as `hw07_yourNetID.html`. For example `hw07_dunger.html`.
- Your resulting `.html` file will be considered a "report" which is the material that will determine the majority of your grade. Be sure to visibly include all `R` code and output that is relevant to answering the exercises. (You do not need to include irrelevant code you tried that resulted in error or did not answer the question correctly.)
- You are granted an unlimited number of submissions, but only the last submission *before* the deadline will be viewed and graded.
- If you use [this `.Rmd` file as a template](hw07.Rmd), be sure to remove the directions section. Consider removing `eval = FALSE` from any code chunks provided in the template, if you would like to run that code as part of your assignment.
- Your `.Rmd` file should be written such that, if it is placed in a folder with any data your are asked to import, it will knit properly without modification.
- Unless otherwise stated, you may use `R` for each of the exercises.
- Be sure to read each exercise carefully!
- Include your Name and NetID in the final document, not only in your filenames.

# Assignment

## Exercise 1 (Nutrition Data revisited)

For this exercise we will use the data stored in [`nutrition.csv`](nutrition.csv) previously seen in HW04. It contains the nutritional values per serving size for a large variety of foods as calculated by the USDA. It is a cleaned version totaling 5,138 observations and is current as of September 2015.

The variables in the dataset are:

- `ID` 
- `Desc` - Short description of food
- `Water` - in grams
- `Calories` 
- `Protein` - in grams
- `Fat` - in grams
- `Carbs` - Carbohydrates, in grams
- `Fiber` - in grams
- `Sugar` - in grams
- `Calcium` - in milligrams
- `Potassium` - in milligrams
- `Sodium` - in milligrams
- `VitaminC` - Vitamin C, in milligrams
- `Chol` - Cholesterol, in milligrams
- `Portion` - Description of standard serving size used in analysis

**(a)** Fit the following multiple linear regression model in `R`. Use `Calories` as the response and `Carbs`, `Fat`, and `Protein` as predictors.

\[
Y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \beta_3 x_{i3} + \epsilon_i.
\]

Here,

- $Y_i$ is `Calories`
- $x_{i1}$ is `Carbs`
- $x_{i2}$ is `Fat`
- $x_{i3}$ is `Protein`.

Use an $F$-test to test the significance of the regression. This is a repeat of a previous exercise, but is here again only as a reminder. This time report only the following:
 
- The p-value of the test.
- A statistical decision at $\alpha = 0.01$.
- A conclusion in the context of the problem.

When reporting these, you should explicitly state them in your document, not assume that a reader will find and interpret them from a large block of `R` output.

```{r}
`nutrition` <- read.csv("~/Downloads/nutrition(1).csv", comment.char="#")
```

```{r}
calories_model = lm(Calories~Carbs+Fat+Protein, data=nutrition)
calories_model_null = lm(Calories~1, data = nutrition)
anova(calories_model_null,calories_model)
```

###### The p-value of the test is very small at < 2.2e-16

###### Because the p-value is so small, we reject the null hypothesis at an alpha level of 0.01

###### Therefore, at least one of the variables from the calories_model has a useful linear relationship with Calories

**(b)** Check the constant variance assumption for this model. Do you feel it has been violated? Justify your answer.

```{r}
plot(fitted(calories_model),resid(calories_model), col="dodgerblue",xlab="Fitted",ylab="Residual")
abline(h=0,col="darkorange",lwd=2)
```

###### The constant variance has been violated because if you notice, the spread of residuals is larger towards the smaller fitted values and the middle fitted values. The overall spread is not constant.

**(c)** Check the normality assumption for this model. Do you feel it has been violated? Justify your answer.

```{r}
set.seed(110116) 
resid5000 = sample(resid(calories_model), 5000)
shapiro.test(resid5000)
```

###### Then null hypothesis assumes the data follows a normal distribution. Because the p-value is so small, we reject the null hypothesis. The normality assumption of this model does not hold.

**(d)** Check for any high leverage observations. Report any observations you determine to have high leverage.

```{r}
calories_lev_model = lm(Calories~Carbs+Fat+Protein, data = nutrition)
high_lev_obs = hatvalues(calories_lev_model) > 2 * mean(hatvalues(calories_lev_model))
```

###### Number of high leverage observations

```{r}
length(hatvalues(calories_lev_model)[high_lev_obs])
```

###### First five high leverage observations 

```{r}
i = 0
arr = rep(0,5)
data = hatvalues(calories_lev_model)[high_lev_obs]
for(i in i:5){
  arr[i] = data[i]
}
arr
```

**(e)** Check for any influential observations. Report any observations you determine to be influential.

```{r}
inf = cooks.distance(calories_lev_model) > 4 / length(cooks.distance(calories_lev_model))
```

###### The number of influential observations 

```{r}
length(cooks.distance(calories_lev_model)[inf])
```

###### The first five influential observations

```{r}
i = 0
arr = rep(0,5)
data = cooks.distance(calories_lev_model)[inf]
for(i in i:5){
  arr[i] = data[i]
}
arr
```

**(f)** Refit the additive multiple regression model without any points you identified as influential. Compare the coefficients of this fitted model to the previously fitted model.

```{r}
calories_add_model = lm(Calories~Carbs+Fat+Protein, data = nutrition, subset = cooks.distance(calories_lev_model) <= 4 / length(cooks.distance(calories_lev_model)))
coef(calories_add_model)
coef(calories_lev_model)
```

## Exercise 2 (Swiss Fertility Data)

For this exercise we will use the `swiss` data which can be found in the `faraway` package. After loading the `faraway` package, use `?swiss` to learn about this dataset.

```{r, message = FALSE, warning = FALSE}
library(faraway)
```

**(a)** Fit an additive multiple regression model with `Fertility` as the response, and the remaining variables in the `swiss` dataset as predictors. Output the estimated regression coefficients for this model.

```{r}
fertility_model = lm(Fertility ~ Agriculture+Examination+Education+Catholic+Infant.Mortality, data = swiss)
coef(fertility_model)
```

**(b)** Check the constant variance assumption for this model. Do you feel it has been violated? Justify your answer.

```{r}
plot(fitted(fertility_model),resid(fertility_model), col="dodgerblue",xlab="Fitted",ylab="Residual")
abline(h=0,col="darkorange",lwd=2)
```

###### Based on the plot, there seems to be a constant variance around the fitted values between 50-90. It isn't perfect, however for the most part the spread is distributed evenly. 

**(c)** Check the normality assumption for this model. Do you feel it has been violated? Justify your answer.

```{r}
shapiro.test(resid(fertility_model))
```

###### Then null hypothesis assumes the data follows a normal distribution. Because the p-value is large, we do not reject the null hypothesis. The normality assumption of this model holds.

**(d)** Check for any high leverage observations. Report any observations you determine to have high leverage.

```{r}
fert_lev_model = lm(Fertility ~., data = swiss)
high_lev_obs = hatvalues(fert_lev_model) > 2 * mean(hatvalues(fert_lev_model))
hatvalues(fert_lev_model)[high_lev_obs]
```

**(e)** Check for any influential observations. Report any observations you determine to be influential.

```{r}
inf = cooks.distance(fert_lev_model) > 4 / length(cooks.distance(fert_lev_model))
cooks.distance(fert_lev_model)[inf]
```

**(f)** Refit the additive multiple regression model without any points you identified as influential. Compare the coefficients of this fitted model to the previously fitted model.

```{r}
fert_add_model = lm(Fertility ~ Agriculture+Examination+Education+Catholic+Infant.Mortality, data = swiss, subset = cooks.distance(fert_lev_model) <= 4 / length(cooks.distance(fert_lev_model)))
coef(fert_add_model)
coef(fert_lev_model)
```

**(g)** Create a data frame that stores the observations that were "removed" because they were influential. Use the two models you have fit to make predictions with these observations. Comment on the difference between these two sets of predictions.

```{r}
Agriculture = c(swiss["Porrentruy","Agriculture"], swiss["Sierre","Agriculture"],swiss["Neuchatel","Agriculture"],swiss["Rive Droite","Agriculture"],27.7)

Examination = c(swiss["Porrentruy","Examination"], swiss["Sierre","Examination"],swiss["Neuchatel","Examination"],swiss["Rive Droite","Examination"],22)

Education = c(swiss["Porrentruy","Education"], swiss["Sierre","Education"],swiss["Neuchatel","Education"],swiss["Rive Droite","Education"],29)

Catholic = c(swiss["Porrentruy","Catholic"], swiss["Sierre","Catholic"],swiss["Neuchatel","Catholic"],swiss["Rive Droite","Catholic"],58.33)

Infant.Mortality = c(swiss["Porrentruy","Infant.Mortality"], swiss["Sierre","Infant.Mortality"],swiss["Neuchatel","Infant.Mortality"],swiss["Rive Droite","Infant.Mortality"],19.3)

newData = data.frame(Agriculture,Examination,Education,Catholic,Infant.Mortality)

predict(fert_lev_model,newdata = newData)
predict(fert_add_model,newdata = newData)
```

###### The two models are pretty close, however in general, the fert_add_model (the subset model) seems to have higher predictions than the whole model. 

## Exercise 3 (Writing Functions)

**(a)** Write a function that takes as input a model object (variable) fit via `lm()` and outputs a fitted versus residuals plot. Also create arguments `pointcol` and `linecol` which control the point and line colors respectively. Code the plot to add a horizontal line at $y = 0$ and label the $x$-axis "Fitted" and the $y$-axis "Residuals".

```{r}
pointcol = c("dodgerblue")
linecol = c("darkorange")
myFunctionResid = function(myModel,pointcol,linecol){
  plot(fitted(myModel),resid(myModel),col=pointcol,xlab="Fitted",ylab="Residuals",main = "Fitted vs Residuals")
abline(h=0,col=linecol,lwd=2)
}
```

**(b)** Write a function that takes as input a model fit via `lm()` plots a Normal Q-Q plot of the residuals. Also create arguments `pointcol` and `linecol` which control the point and line colors respectively. Code the plot to add the line from `qqline()`.

```{r}
pointcol = c("dodgerblue")
linecol = c("darkorange")
myFunctionNorm = function(myModel,pointcol,linecol){
  qqnorm(resid(myModel), main = "Normal Q-Q Plot", col = pointcol)
  qqline(resid(myModel), col = linecol, lwd = 2)
}
```

**(c)** Test your two functions above on the `test_fit` model. For both functions, specify point and line colors that are not black.

```{r}
set.seed(120168)
test_data = data.frame(x = runif(20, 0, 10),
                       y = rep(0, 20))
test_data$y = 5 + 2 * test_data$x + rnorm(20)
test_fit = lm(y ~ x, data = test_data)
```

```{r}
pointcol = c("dodgerblue")
linecol = c("darkorange")
myFunctionResid(test_fit,pointcol,linecol)
myFunctionNorm(test_fit,pointcol,linecol)
```

## Exercise 4 (Why Bother with Assumptions?)

**Why** do we care about violations of assumptions? One key reason is that the distributions of the parameters that we have used are all reliant on these assumptions. When the assumptions are violated, the distributional results are not correct, so are tests are garbage. **Garbage In, Garbage Out!**

Consider the following setup that we will use for the remainder of the exercise. We choose a sample size of 50.

```{r}
n = 50
set.seed(123)
x_1 = runif(n, 0, 10)
x_2 = runif(n, -5, 5)
```

Consider the model,

\[
Y = 2 + 1 x_1 + 0 x_2 + \epsilon.
\]

That is,

- $\beta_0$ = 2,
- $\beta_1$ = 1,
- $\beta_2$ = 0.

We now simulate `y_1` in a manner that doesn't violate any assumptions, which we verify. In this case $\epsilon \sim N(0, 1).$

```{r}
y_1   = 2 + x_1 + 0 * x_2 + rnorm(n)
fit_1 = lm(y_1 ~ x_1 + x_2)
qqnorm(resid(fit_1), col = "dodgerblue")
qqline(resid(fit_1), col = "darkorange", lwd = 2)
shapiro.test(resid(fit_1))
```

Then, we simulate `y_2` in a manner that **does** violate assumptions, which we verify. In this case $\epsilon \sim N(0, \sigma = |x_2|).$

```{r}
y_2   = 2 + x_1 + 0 * x_2 + rnorm(n, 0, abs(x_2))
fit_2 = lm(y_2 ~ x_1 + x_2)
qqnorm(resid(fit_2), col = "dodgerblue")
qqline(resid(fit_2), col = "darkorange", lwd = 2)
shapiro.test(resid(fit_2))
```

**(a)** Use the following code after changing `uin` to your UIN.

```{r}
num_sims = 1000
p_val_1 = rep(0, num_sims)
p_val_2 = rep(0, num_sims)
uin = 673345364
set.seed(uin)
```

Repeat the above process of generating `y_1` and `y_2` as defined above, and fit models with each as the response `1000` times. Each time, store the p-value for testing,

\[
\beta_2 = 0,
\]

using both model, in the appropriate variables defined above. (You do not need to use a data frame as we have in the past.)

```{r}
num_sims = 1000
p_val_1 = rep(0, num_sims)
p_val_2 = rep(0, num_sims)
uin = 673345364
set.seed(uin)

n = 50
x1 = runif(n,0,10)
x2 = runif(n,-5,5)

i = 0
for(i in i:num_sims){
  y1 = 2 * x1 + 0*x2 + rnorm(n)
  fit1 = lm(y1 ~ x1+x2)
  
  y2 = 2 * x1 + 0*x2 + rnorm(n,0,abs(x2))
  fit2 = lm(y2 ~ x1+x2)
  
  p_val_1[i] = shapiro.test(resid(fit1))[2]
  p_val_2[i] = shapiro.test(resid(fit2))[2]
}
```

**(b)** What proportion of the `p_val_1` values are less than 0.05? Less than 0.10? What proportion of the `p_val_2` values are less than 0.05? Less than 0.10? Briefly explain these results.

###### proportion p_val_1 is less than 0.05
```{r}
mean(p_val_1 < 0.05)
```

###### proportion p_val_2 is less than 0.05
```{r}
mean(p_val_2 < 0.05)
```

###### proportion p_val_1 is less than 0.10
```{r}
mean(p_val_1 < 0.10)
```

###### proportion p_val_1 is less than 0.10
```{r}
mean(p_val_2 < 0.10)
```
